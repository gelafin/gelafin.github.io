3/28{
format home header - 
	center
update font sizes - 
	*2rem for nav titles and section titles (for other pages 	that 	have sections rather than big nav)
	*1.5rem for subtitle
	*2rem for site title for now
set fonts
	use a Google font
format margins
	center main content
	add media query @600px
set vertical spacing
}

4/3 {
YayReplay css is not loading. It worked once, added to it, now doesn't work. Didn't change path.
}

4/4 {
YayReplay css path was still not right. Fixed. Also removed a duplicate css file.
}

4/6 {
JS test didn't work. Chrome said var target was null, which means querySelector() didn't work. Will check querySelector() on MDN or else use different tutorial.
}

4/7{
JS test worked. Trying to set up Babel so simple import statement will work in js file. Could use the ES5 version like require(), but Tim said it's cooler and should be done.

Progress: "npm run build" command completed successfully.
At: https://babeljs.io/setup#installation step 4 (using CLI).

Note: May also be helpful to finish guide at https://wesbos.com/javascript-modules/

Note: Tim also recommends Webpack, but idk if necessary.
}

4/8{
still get "Uncaught SyntaxError: Cannot use import statement outside a module". SO said just add "type": "module" to package.json but that didn't fix it.
}

4/9{
realized the Babel setup guide wasn't completed yet. Made .babelrc to enable the preset-env, but that also didn't work. Maybe will have to add a start script like SO says here: https://stackoverflow.com/questions/58805918/why-node-js-ignores-the-type-setting-in-the-package-json-file. That didn't work either.

Tim says it's too hard to troubleshoot, just use old style.
}

4/10{
reverted repo and noticed node_modules was tiny because untracked. Will just delete node_modules and reinstall node and Papaparse. Deleted node_modules but still says I have npm installed globally. Don't remember how to install npm locally
}

4/11{
working commit 1565afc copied all of papaparse/ into js/ and used script tag in html to load js/papaparse/papaparse.min.js. Since people say not to use the actual path for security, will look into dep-linker later.

Progress: time to fix the csv writerow bug :). Once there is something consistent to upload, need to either copy the whole database to the GitHub Pages folder or change the path in the step that saves to csv, so the database is just kept in the GP folder instead of the scraper folder.
}

4/14{
fixed writerow bug in scraper and also got scraper.py to write to the database in YayReplay's assets folder. Ready to parse.

File paths in js files are relative to the html file their script tag is in. That would have taken a while without Tim.

Tim also helped with callback function. Better to pass a reference to the function parse(functionName) instead of calling it from inside like parse(functionName(data)). Yes, Papaparse secretly passes results as an argument to functionName when it calls back. The other examples with paretheses were all anonymous, which is why that worked.

It's alive for the first time, showing scraped data on the web page.

Progress: parsedObject.data returns array of rows. For some reason, it gets an extra null row, so might work around for now by adding a check if the row is null before creating its element. ParsedObject.errors is showing FieldMismatch: TooFewFields. Fixed by adding a config argument.

New progress: use f12 to set equal width either with max-width % or max-width px or (on container) justify-content space-evenly. Then, add a function to print the headers. Then, add something to set the element of links to anchors instead of div after main loop (or at worst use if in main loop).
}

4/15{
setting margin-right px on the child divs works.

Progress: headers (done), anchors should link and say "link to Play page" (done), don't print id (done).

Progress: format headers so they are the same width as the below divs. Maybe use table tag instead of flexbox. No, will make the header columns into flex containers and not apply row spacing to data (but that might throw off vertical alignment). Actually, best to get pictures before deciding, because that will play a large part. One good point is that tables are more semantic than flexbox.

Target blank the links. (done)

Progress: add pictures. Done.

New Progress: scrape genre next, because that will affect layout.

layout: organize blocks of each genre. Pray Pray says each game should only show picture, price, rating. The rest will be revealed with expanding arrow (or something that keeps user on page) if you click the picture.
}

4/16{
layout goal: very simple table and media query, no flexbox needed. Will organize blocks by genre and have basic button to load preview images and details. Will reorder dict before writing to csv so elements are in order.

Will create invisible rows below each gameRow to hold screenshots and video. Done.

new progress: 1) reorder dict 2) load one table of 5 results per genre. If user clicks details arrow button, hiddenDiv items are loaded for that game only.
}

4/17{
progress: 
1) reorder dict DONE 

2a) scrape the whole store using sitemap (check first if sitemap includes an abundance of collections pages that can be scraped, then check storage capacity for so many data, then check how to get more than 49 results per collections page). Have one database per genre. According to freshGame["genre"], save to that genre's database. (ADDED ISSUE for later)

2b) load one table of 10 results per genre. If user clicks details arrow button, hiddenDiv items are shown for that game only. 
  -> should only have columns, not rows at all. But set a class with set height on each item.

  -> if so, change one database or have multiple databases organized differently or just use JS each time "load more" happens to search the whole database until finding enough new things?
    -> ONE database for now. Will add Steam games with Postgres first bc it's easier than adding the rest of GPlay with sitemaps. And will only have one table on Postgres, Tim said.

  -> ask: if not getting all games and using original 2 view above, what should be the default view? ONLY USE TOP CATEGORIES. (maybe use separate databases for those even though it's temporary). Load first 25 results and a "show more" button at the bottom. No second web page.

3) if rating reasons is learn more don't print it.

4) add filter buttons that calls upload function again with new filters list as a parameter (or calls a separate function that refreshes it)

5) add fuzzy search

New progress:
1. Format enough to be useful for only a few games:
  a. Replace row structure with column-only structure
    1. Create empty column divs (DONE)
    2. Loop through columns and add each element
      a. For text-only non-hidden columns, make a dict that maps each to its cssId. (DONE)
      b. make the dict know if something is hidden for l. 72 (DONE enough for testing)
    3. Every element has a class that assigns fixed height (DONE)
    4. How to make details expand without covering below game?
      a. could add margin-below class plus show hidden horizontal div. 
      b. Will need to set relative position to make sure it goes in the right place and set z-index so it doesn't interact with layout at all. (DONE)

  b. Load first 25 results and a "show more" button at the bottom. No second page.

  c. Filter buttons at the top of certain columns
    1. Only for genre, rating, ratingReasons. (StarRating and price will need special treatment, so wait until after Steam.)
    2. Filter button reveals a drop-down of filter options with Apply button at the bottom.
      a. Each option in the drop-down has a checkbox next to it. Checking a box just calls setFilter(filter, addOrRemove).
      b. There's an "Apply" button at the bottom of the drop-down list that calls uploadData(filters).
    4. Refresh function just loads the first 25 games that meet the criteria

2. Fuzzy Search options
  a. https://github.com/atom/fuzzaldrin/
  b. https://github.com/farzher/fuzzysort

3. Steam
  a. Postgres
}

4/18{
above. Progress: hiddenrow does not appear after a game. Check loop scope and relative position.

move script tags after body
}

4/19{
changing progress to 1.b. Will use Papaparse's step. parser.pause() will be called after 50 results are loaded, and parser.resume() will be called by a button at the bottom. Which means do a regular for loop 25 times and then add a check at the top of the loop for a null result, in which case change button text to "all games showing" and gray it out (change tag to <button disabled>).

add button in HTML after columns so it's always at bottom

Papaparse.parse(...{step: uploadPlayData})

uploadPlayData():
  for (let index = 0; index < 25; index++):
    for each column...add to HTML column
    parser.pause()

(button calls parser.resume())

invisible not showing up at all when child of img, but codepen shows that's not the reason.

Probably should call Papaparse.parse inside a for loop to achieve button loading
}

4/21{
just go back to rows and set column width on each element in that column. Rows will enable hidden row to be toggled with display:none

Chunksize is very large. One user reported 40,000 does 300 rows-ish, and this chunk is 5M+. Could set a smaller chunk size, or could use a loop. Will test this to make "more" button...

manager object
  var totalRowCounter = 1 //must start at 1 bc compares to array.length below
  var chunkRowsUploaded = 0 // keeps track of the 50 to avoid bug where like 40 results load and then oh no there's no more time to resume and resume calls upload50 from the beginning, which loads 50+40 from before = 90 results in one button press.

/*DONE making manager*/

papa.parse(manager.upload50(), pause()) // get a big ol 5MB chunk and upload 50 rows of it and immediately pause, not using the rest of the chunk

manager.upload50:

  for (let index = chunkRowsUploaded; index < 50; index++, manager.totalRowCounter++) //loop 50 times to upload 50 rows, unless this function is being called after a resume(), which interrupted the count. In that case, make index not from 0 but from whatever row it was on before and continue until 50.
  //but first, make sure a row is available
  if no more // totalRowCounter == parser.streamer._rowCount OR parsedObject.data.length() // _rowCount is more efficient but .length() may be the only available option
  parser.resume // return from this function and resume, which calls this function again as the chunk callback

  if parsedObject.data[manager.totalRowCounter] != null:
    parsedObject.data[manager.totalRowCounter] //resume uploading the existing chunk from the current row
  else:
    print "no more!";
    gray out button;
    return;

chunkRowsUploaded = 0 // after loop completes 50 times, it's done

LOAD MORE button:
  calls manager.upload50
}